"""Second Brain - unified memory management.

This module integrates the two-partition memory system: active context window
and long-term memory. It provides a unified interface for storing and retrieving
memories across both partitions.
"""

from typing import List, Dict, Any

from astro.core.memory.context_window import ContextWindow
from astro.core.memory.long_term import LongTermMemory


class SecondBrain:
    """Second Brain - two-partition memory system.

    Integrates context window (Partition 1) and long-term memory (Partition 2)
    into a unified memory system. Enables:
    - Recall previous answers to similar questions
    - Learn which directives work for which queries
    - Build up knowledge over time
    - RAG-like behavior without explicit RAG

    Both partitions support READ (retrieval) and WRITE (storage).

    The Second Brain is the core memory system for Astro V2. It automatically
    manages conversation context and long-term knowledge, making the system
    smarter over time without manual intervention.

    Example:
        # Create Second Brain
        context_window = ContextWindow(max_chars=50000)
        long_term = LongTermMemory(
            backend=memory_backend,
            embedding_provider=embeddings,
        )
        second_brain = SecondBrain(context_window, long_term)

        # Store result (writes to both partitions)
        await second_brain.store(
            content="Tesla Q4 2024 revenue: $25.2B, up 15% YoY",
            metadata={
                "query": "Tesla Q4 revenue",
                "directives": ["financial_analysis"],
                "timestamp": "2024-01-15"
            }
        )

        # Retrieve context (reads from both partitions)
        context = await second_brain.retrieve(
            queries=["Tesla revenue", "Tesla financial performance"],
            conversation=conversation_obj
        )

        # Context includes:
        # - long_term: Semantically similar memories from past queries
        # - recent: Recent messages from active conversation
    """

    def __init__(
        self,
        context_window: ContextWindow,
        long_term: LongTermMemory,
    ):
        """Initialize Second Brain.

        Args:
            context_window: Partition 1 (active context)
            long_term: Partition 2 (long-term memory)
        """
        self.context_window = context_window  # Partition 1
        self.long_term = long_term            # Partition 2

    async def retrieve(
        self,
        queries: List[str],
        conversation: Any = None,  # type: ignore
    ) -> Dict[str, Any]:
        """READ: Retrieve context from both partitions.

        This method is used in Step 2 of the zero-shot pipeline to gather
        relevant context for the running agent.

        Args:
            queries: List of search queries for long-term memory
                    (typically generated by the Interpreter in Step 1)
            conversation: Current conversation object (for recent context)

        Returns:
            Dict with two keys:
            - long_term: List of relevant memories from vector search
            - recent: List of recent messages from context window

        Example:
            # In Step 2 of zero-shot pipeline
            context = await second_brain.retrieve(
                queries=["Tesla revenue Q4", "Tesla financial metrics"],
                conversation=current_conversation
            )

            # Use context in Step 3 (running agent)
            result = await running_agent.execute(
                directives=selected_directives,
                conversation=conversation,
                context=context  # Contains both long-term and recent
            )
        """
        # Query long-term memory (vector search)
        long_term_memories = []
        for query in queries:
            memories = await self.long_term.retrieve(query, limit=3)
            long_term_memories.extend(memories)

        # Get recent context from context window
        recent = self.context_window.get_recent(limit=10)

        return {
            "long_term": long_term_memories,
            "recent": recent,
        }

    async def store(
        self,
        content: str,
        metadata: Dict[str, Any],
    ) -> None:
        """WRITE: Store result in both partitions.

        This method is used in Step 4 of the zero-shot pipeline to persist
        the execution result for future retrieval.

        Stores in both partitions:
        - Long-term memory: For semantic search in future queries
        - Context window: For immediate conversation context

        Args:
            content: Text content to store (typically the execution result)
            metadata: Metadata to attach (query, directives, timestamp, etc.)

        Example:
            # In Step 4 of zero-shot pipeline
            await second_brain.store(
                content=execution_result.output,
                metadata={
                    "query": user_query,
                    "directives": [d.id for d in selected_directives],
                    "timestamp": datetime.utcnow().isoformat(),
                    "tool_calls": len(execution_result.tool_calls),
                }
            )

            # Now this result can be retrieved in future similar queries
        """
        # Store in long-term (for future retrieval)
        await self.long_term.store(content, metadata)

        # Add to active context window (for immediate context)
        self.context_window.add_message(content, metadata)

    def add_exchange(
        self,
        user_message: str,
        assistant_message: str,
        metadata: Dict[str, Any] = None,
    ) -> None:
        """Add a user-assistant exchange to context window.

        This is a convenience method for adding conversation turns to
        the active context. Does NOT store in long-term memory.

        Args:
            user_message: User's message
            assistant_message: Assistant's response
            metadata: Optional metadata to attach

        Example:
            # Add conversation exchange
            second_brain.add_exchange(
                user_message="What's Tesla's revenue?",
                assistant_message="Tesla's Q4 2024 revenue was $25.2B",
                metadata={"query_id": "abc123"}
            )
        """
        if metadata is None:
            metadata = {}
        self.context_window.add_exchange(
            user_message=user_message,
            assistant_message=assistant_message,
            metadata=metadata,
        )

    def get_recent_context(self, limit: int = 10) -> List[Any]:
        """Get recent messages from context window.

        Args:
            limit: Maximum number of recent messages

        Returns:
            List of recent messages
        """
        return self.context_window.get_recent(limit=limit)

    def clear_context(self) -> None:
        """Clear the active context window.

        Useful for starting a new conversation or resetting context.
        Does NOT affect long-term memory.
        """
        self.context_window.clear()
